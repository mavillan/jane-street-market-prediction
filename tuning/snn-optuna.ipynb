{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "snn-optuna.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMBlQ8Y2RoVp1pEAvlKRPly",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6535422576ec419a89513393526df5c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_863e3636105d41f8a974c0ebfe8ceab6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ce42af77ab204996b0acd5939a60438c",
              "IPY_MODEL_c843e464b5dc4cde8c33af401bbb05d6"
            ]
          }
        },
        "863e3636105d41f8a974c0ebfe8ceab6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce42af77ab204996b0acd5939a60438c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3731ea34c94c4d2bb4ab13ec09e830a3",
            "_dom_classes": [],
            "description": "SNN:   8%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 50,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c09a355c95224822b39f26c720c96732"
          }
        },
        "c843e464b5dc4cde8c33af401bbb05d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ab2144ab7b6449b2a99a8e00aee46e66",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/50 [03:23&lt;32:57, 42.99s/it, a_train_loss=0.690312, b_valid_loss=0.689236, c_best_loss=0.689236, d_train_metric=-2470.519907, e_valid_metric=-1671.473671, f_best_metric=-1671.473671, g_es_counter=0, h_last_lr=0.03250444]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eaa4f54088754c9399e553b969c1afd5"
          }
        },
        "3731ea34c94c4d2bb4ab13ec09e830a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c09a355c95224822b39f26c720c96732": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab2144ab7b6449b2a99a8e00aee46e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eaa4f54088754c9399e553b969c1afd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mavillan/jane-street-market-prediction/blob/main/tuning/snn-optuna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr8g_8dO6tM9",
        "outputId": "f82e298c-9e9d-4ba2-ffe7-1f1d3c2153a6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYnT8Tmx_-Js"
      },
      "source": [
        "!pip install -Iv scikit-learn==0.23.2 > /dev/null 2>&1\n",
        "!pip install optuna > /dev/null 2>&1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4rwnTOt__ew",
        "outputId": "399c4f9d-2da4-4dd4-b074-0d1d25410d5f"
      },
      "source": [
        "import copy\n",
        "import os\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import optuna\n",
        "\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,TensorDataset,DataLoader\n",
        "\n",
        "# custom modules\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/kaggle/janestreet\")\n",
        "from torch_utils import Monitor, train_step, valid_step\n",
        "\n",
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    \n",
        "set_seed(2)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fk8dRnlBJdO"
      },
      "source": [
        "***\n",
        "### utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVWwthUVA-iS"
      },
      "source": [
        "def utility_score(date, weight, resp, action):\n",
        "    \"\"\"\n",
        "    Fast computation of utility score\n",
        "    \"\"\"\n",
        "    date = date.astype(int)\n",
        "    count_i = len(np.unique(date))\n",
        "    Pi = np.bincount(date, weight * resp * action)\n",
        "    t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / count_i)\n",
        "    u = np.clip(t, 0, 6) * np.sum(Pi)\n",
        "    return -u"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkqWFg7_BMOE"
      },
      "source": [
        "def cat_encoder(X):\n",
        "    \"\"\"\n",
        "    Fast one-hot encoding of feature_0\n",
        "    \"\"\"\n",
        "    X[\"feature_00\"] = 0\n",
        "    idx00 = X.query(\"feature_0 == -1\").index\n",
        "    X.loc[idx00,\"feature_00\"] = 1\n",
        "    \n",
        "    X[\"feature_01\"] = 0\n",
        "    idx01 = X.query(\"feature_0 == 1\").index\n",
        "    X.loc[idx01,\"feature_01\"] = 1\n",
        "    \n",
        "    return X.iloc[:,1:]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr4HjJC_BOae"
      },
      "source": [
        "def show_metrics(monitor):\n",
        "    x = np.arange(len(monitor.train_loss))\n",
        "    \n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(21, 7))\n",
        "    \n",
        "    ax1 = axes[0]\n",
        "    ax2 = ax1.twinx()\n",
        "    ax1.plot(x, monitor.train_loss, 'go-', label=\"train_loss\")\n",
        "    ax2.plot(x, monitor.train_metric, 'ro-', label=\"train_metric\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    ax1.set_xlabel('epochs')\n",
        "    ax1.set_ylabel('loss')\n",
        "    ax1.set_title(\"Training\")\n",
        "    plt.grid()\n",
        "    \n",
        "    ax1 = axes[1]\n",
        "    ax2 = ax1.twinx()\n",
        "    ax1.plot(x, monitor.valid_loss, 'go-', label=\"valid_loss\")\n",
        "    ax2.plot(x, monitor.valid_metric, 'ro-', label=\"valid_metric\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    ax1.set_xlabel('epochs')\n",
        "    ax2.set_ylabel('metric')\n",
        "    ax1.set_title(\"Validation\")\n",
        "    plt.grid()\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apOKLQQ2BSm1"
      },
      "source": [
        "***\n",
        "### preparing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrCJeuBiBQrx",
        "outputId": "3dc5b0e6-817b-44a9-a3a3-c178fcb28234"
      },
      "source": [
        "root = Path(\"/content/drive/MyDrive/kaggle/janestreet/preprocessing/\")\n",
        "\n",
        "train = pd.read_parquet(root/\"train.parquet\")\n",
        "features = pd.read_parquet(root/\"features.parquet\")\n",
        "\n",
        "train.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2390491 entries, 0 to 2390490\n",
            "Columns: 143 entries, date to w4\n",
            "dtypes: float32(140), int16(1), int32(1), int8(1)\n",
            "memory usage: 1.3 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGSvr3QTBiW0"
      },
      "source": [
        "train = train.query(\"date > 85\").query(\"weight > 0\").reset_index(drop=True)\n",
        "\n",
        "input_features = [col for col in train.columns if \"feature\" in col]\n",
        "resp_cols = ['resp', 'resp_1', 'resp_2', 'resp_3', 'resp_4']\n",
        "w_cols = [\"w\", \"w1\", \"w2\", \"w3\", \"w4\"]\n",
        "\n",
        "X_dset = train.loc[:,input_features].copy()\n",
        "y_dset = (train.loc[:,resp_cols] > 0).astype(int).copy()\n",
        "w_dset = train.loc[:, w_cols].copy()\n",
        "dwr_dset = train.loc[:, [\"date\",\"weight\",\"resp\"]].copy()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrvm_YmFBlxK",
        "outputId": "b7b09a2b-4e8f-4f9a-a387-7c97f3c5ec6f"
      },
      "source": [
        "%%time \n",
        "\n",
        "with open(\"/content/drive/MyDrive/kaggle/janestreet/imputer/imputer_f0m1.pickle\", \"rb\") as file:\n",
        "    imputer_f0m1 = pickle.load(file)\n",
        "    file.close()\n",
        "    \n",
        "with open(\"/content/drive/MyDrive/kaggle/janestreet/imputer/imputer_f0p1.pickle\", \"rb\") as file:\n",
        "    imputer_f0p1 = pickle.load(file)\n",
        "    file.close()\n",
        "\n",
        "idx_f0m1 = X_dset.query(\"feature_0 == -1\").index\n",
        "X_dset.loc[idx_f0m1, input_features[1:]] = imputer_f0m1.transform(X_dset.loc[idx_f0m1, input_features[1:]])\n",
        "\n",
        "idx_f0p1 = X_dset.query(\"feature_0 ==  1\").index\n",
        "X_dset.loc[idx_f0p1, input_features[1:]] = imputer_f0p1.transform(X_dset.loc[idx_f0p1, input_features[1:]])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 48.7 s, sys: 9.98 s, total: 58.7 s\n",
            "Wall time: 50.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz1p9G7-B2jm"
      },
      "source": [
        "X_dset = cat_encoder(X_dset)\n",
        "input_features = X_dset.columns.tolist()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bshDOMpTB3uw"
      },
      "source": [
        "***\n",
        "### model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mtkhl3nB3OX"
      },
      "source": [
        "class GBN(nn.Module):\n",
        "    \"\"\"\n",
        "    Ghost Batch Normalization\n",
        "    https://arxiv.org/abs/1705.08741\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, virtual_batch_size=128, momentum=0.01):\n",
        "        super(GBN, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.virtual_batch_size = virtual_batch_size\n",
        "        self.bn = nn.BatchNorm1d(self.input_dim, momentum=momentum)\n",
        "\n",
        "    def forward(self, x):\n",
        "        chunks = x.chunk(int(np.ceil(x.shape[0] / self.virtual_batch_size)), 0)\n",
        "        res = [self.bn(x_) for x_ in chunks]\n",
        "\n",
        "        return torch.cat(res, dim=0)\n",
        "\n",
        "class NormalLinear(nn.Module):\n",
        "    \"\"\" \n",
        "    Linear layer with normalized weights\n",
        "    \"\"\"\n",
        "    def __init__(self, size_in, size_out, bias=True):\n",
        "        super().__init__()\n",
        "        self.size_in, self.size_out = size_in, size_out\n",
        "        # weights vector\n",
        "        weights_v = torch.Tensor(size_out, size_in)\n",
        "        nn.init.kaiming_uniform_(weights_v, a=np.sqrt(5)) \n",
        "        self.weights_v = nn.Parameter(weights_v)\n",
        "        # weights magnitude\n",
        "        weights_m = torch.norm(weights_v, dim=1, keepdim=True)\n",
        "        self.weights_m = nn.Parameter(weights_m)\n",
        "        \n",
        "        if bias:\n",
        "            bias_v = torch.Tensor(size_out)    \n",
        "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(weights_v)\n",
        "            bound = 1 / np.sqrt(fan_in)\n",
        "            nn.init.uniform_(bias_v, -bound, bound)\n",
        "            self.bias = nn.Parameter(bias_v)\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        \n",
        "        self._normalize_weights()\n",
        "            \n",
        "    def _normalize_weights(self):\n",
        "        with torch.set_grad_enabled(False):\n",
        "            norm_per_output = torch.norm(self.weights_v, dim=1, keepdim=True)\n",
        "            self.weights_v.div_(norm_per_output)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        self._normalize_weights()\n",
        "        return nn.functional.linear(x, self.weights_v * self.weights_m, self.bias)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6YRV9RrB-5g"
      },
      "source": [
        "class SNN(nn.Module):\n",
        "    \"\"\"\n",
        "    SNN for pretraining\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, output_dim, nn_depth, nn_width, dropout, momentum=0.02, virtual_batch_size=128):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.bn_in = GBN(input_dim, virtual_batch_size=virtual_batch_size, momentum=momentum)\n",
        "        self.dp_in = nn.Dropout(dropout)\n",
        "        self.ln_in = NormalLinear(input_dim, nn_width, bias=False)\n",
        "        \n",
        "        self.bnorms = nn.ModuleList(\n",
        "            [GBN(nn_width, virtual_batch_size=virtual_batch_size, momentum=momentum) \n",
        "             for i in range(nn_depth-1)])\n",
        "        self.dropouts = nn.ModuleList(\n",
        "            [nn.Dropout(dropout) \n",
        "             for i in range(nn_depth-1)])\n",
        "        self.linears = nn.ModuleList(\n",
        "            [NormalLinear(nn_width, nn_width, bias=False) \n",
        "             for i in range(nn_depth-1)])\n",
        "        \n",
        "        self.bn_out = GBN(nn_width, virtual_batch_size=virtual_batch_size, momentum=momentum)\n",
        "        self.dp_out = nn.Dropout(dropout/2)\n",
        "        self.ln_out = NormalLinear(nn_width, output_dim, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn_in(x)\n",
        "        x = self.dp_in(x)\n",
        "        x = self.ln_in(x)\n",
        "        x = nn.functional.relu(x)\n",
        "\n",
        "        for bn_layer,dp_layer,ln_layer in zip(self.bnorms,self.dropouts,self.linears):\n",
        "            x = bn_layer(x)\n",
        "            x = dp_layer(x)\n",
        "            x = ln_layer(x)\n",
        "            x = nn.functional.relu(x)\n",
        "            \n",
        "        x = self.bn_out(x)\n",
        "        x = self.dp_out(x)\n",
        "        x = self.ln_out(x)\n",
        "        return x"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypiBNQQ5CG0o"
      },
      "source": [
        "class BCELabelSmoothing(nn.Module):\n",
        "    def __init__(self, label_smoothing=0.0):\n",
        "        super(BCELabelSmoothing, self).__init__()\n",
        "        self.label_smoothing = label_smoothing\n",
        "        self.bce_loss = torch.nn.functional.binary_cross_entropy_with_logits\n",
        "        \n",
        "    def forward(self, prediction, target, weight=None):\n",
        "        target_smooth = target*(1.0 - self.label_smoothing) + 0.5*self.label_smoothing\n",
        "        if weight is None:\n",
        "            loss = self.bce_loss(prediction, target_smooth, reduction=\"mean\")\n",
        "        else:\n",
        "            loss = self.bce_loss(prediction, target_smooth, weight, reduction=\"sum\") / torch.sum(weight)\n",
        "        return loss\n",
        "\n",
        "bce_loss = BCELabelSmoothing(label_smoothing=1e-2)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZIUqLHZCKzo"
      },
      "source": [
        "***\n",
        "### Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuU6IXiNB3V5",
        "outputId": "959822aa-5f83-45e4-cb04-4b272807df73"
      },
      "source": [
        "# 80% rows for train & 20% for valid\n",
        "train_idx = train.query(\"date < 430\").index\n",
        "valid_idx = train.query(\"date >= 430\").index\n",
        "\n",
        "train_dset = TensorDataset(torch.tensor(X_dset.loc[train_idx].values, dtype=torch.float), \n",
        "                           torch.tensor(y_dset.loc[train_idx].values, dtype=torch.float),\n",
        "                           torch.tensor(w_dset.loc[train_idx].values, dtype=torch.float),\n",
        "                           torch.tensor(dwr_dset.loc[train_idx].values, dtype=torch.float),\n",
        "                          )\n",
        "\n",
        "valid_dset = TensorDataset(torch.tensor(X_dset.loc[valid_idx].values, dtype=torch.float), \n",
        "                           torch.tensor(y_dset.loc[valid_idx].values, dtype=torch.float),\n",
        "                           torch.tensor(w_dset.loc[valid_idx].values, dtype=torch.float),\n",
        "                           torch.tensor(dwr_dset.loc[valid_idx].values, dtype=torch.float),\n",
        "                          )\n",
        "\n",
        "dataset_sizes = {'train': len(train_dset), 'valid': len(valid_dset)}\n",
        "train_dataloader = DataLoader(train_dset, batch_size=2048, shuffle=True, num_workers=2)\n",
        "valid_dataloader = DataLoader(valid_dset, batch_size=len(valid_dset), shuffle=False, num_workers=2)\n",
        "\n",
        "print(\"Number of step per epoch:\", len(train_dset)//2048)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of step per epoch: 612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "178O3aGDCJyH"
      },
      "source": [
        "if os.path.exists(f\"/content/drive/MyDrive/kaggle/janestreet/logs/snn_tuning.csv\"):\n",
        "    logger = open(f\"/content/drive/MyDrive/kaggle/janestreet/logs/snn_tuning.csv\", \"a\")\n",
        "else:\n",
        "    logger = open(f\"/content/drive/MyDrive/kaggle/janestreet/logs/snn_tuning.csv\", \"w\")\n",
        "    logger.write(\"trial;params;loss;metric;loss_hist;metric_hist\\n\")"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHRlUdCRD4k9"
      },
      "source": [
        "default_nn_kwargs = {\n",
        "    \"input_dim\":len(input_features),\n",
        "    \"output_dim\":len(resp_cols),\n",
        "    \"nn_depth\":4,\n",
        "    }\n",
        "\n",
        "def objective(trial):\n",
        "    sampled_nn_kwargs = {\n",
        "        #\"nn_depth\": trial.suggest_int(\"nn_depth\", 3, 5)\n",
        "        \"nn_width\": int(trial.suggest_discrete_uniform(\"nn_width\", 64, 192, 16)),\n",
        "        \"dropout\": trial.suggest_discrete_uniform(\"nn_dropout\", 0.1, 0.5, 0.05),\n",
        "        \"momentum\": trial.suggest_discrete_uniform(\"momentum\", 0.01, 0.1, 0.01),\n",
        "        \"virtual_batch_size\": 2 ** trial.suggest_int(\"virtual_batch_size\", 7, 10),\n",
        "        }\n",
        "    nn_kwargs = {**sampled_nn_kwargs, **default_nn_kwargs}\n",
        "\n",
        "    # other hyperparams\n",
        "    weight_decay = 10 ** trial.suggest_int(\"weight_decay\", -6, -2)\n",
        "    pct_start = trial.suggest_discrete_uniform(\"pct_start\", 0.1, 0.5, 0.1)\n",
        "\n",
        "    sampled_params = {\n",
        "        **sampled_nn_kwargs,\n",
        "        \"weight_decay\":weight_decay,\n",
        "        \"pct_start\":pct_start,\n",
        "        }\n",
        "    print(\"-\"*80)\n",
        "    print(\"sampled_params:\", sampled_params)\n",
        "\n",
        "    model = SNN(**nn_kwargs)\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=5e-2, momentum=0.9, weight_decay=weight_decay)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer, \n",
        "        max_lr=1e-1,\n",
        "        epochs=50,\n",
        "        pct_start=pct_start, \n",
        "        anneal_strategy='cos', \n",
        "        cycle_momentum=True, \n",
        "        base_momentum=0.8, \n",
        "        max_momentum=0.9, \n",
        "        div_factor=1e1,\n",
        "        final_div_factor=1e0,\n",
        "        steps_per_epoch=len(train_dataloader),\n",
        "        verbose=False)\n",
        "    \n",
        "    monitor = Monitor(\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        scheduler=scheduler,\n",
        "        patience=10,\n",
        "        metric_fn=utility_score,\n",
        "        experiment_name=f'SNN',\n",
        "        num_epochs=50,\n",
        "        dataset_sizes=dataset_sizes,\n",
        "        early_stop_on_metric=False,\n",
        "        lower_is_better=True)\n",
        "    \n",
        "    for epoch in monitor.iter_epochs:\n",
        "        train_step(model, train_dataloader, optimizer, monitor, bce_loss, scheduler=scheduler, clip_value=None)    \n",
        "        early_stop = valid_step(model, valid_dataloader, optimizer, monitor, bce_loss)\n",
        "        if early_stop: break\n",
        "\n",
        "    logger.write(f\"{trial.number};{sampled_params};{monitor.best_loss};{monitor.best_metric};{monitor.valid_loss[-10:]};{monitor.valid_metric[-10:]}\\n\")\n",
        "    logger.flush()\n",
        "\n",
        "    print(f\"best_valid_loss: {monitor.best_loss} - best_valid_metric: {monitor.best_metric}\")\n",
        "    return monitor.best_loss"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127,
          "referenced_widgets": [
            "6535422576ec419a89513393526df5c2",
            "863e3636105d41f8a974c0ebfe8ceab6",
            "ce42af77ab204996b0acd5939a60438c",
            "c843e464b5dc4cde8c33af401bbb05d6",
            "3731ea34c94c4d2bb4ab13ec09e830a3",
            "c09a355c95224822b39f26c720c96732",
            "ab2144ab7b6449b2a99a8e00aee46e66",
            "eaa4f54088754c9399e553b969c1afd5"
          ]
        },
        "id": "2rvn1v1eM9_N",
        "outputId": "7efef3fe-7956-4c0d-862f-1f42d174fc88"
      },
      "source": [
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=200, timeout=43200, show_progress_bar=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-02-16 05:02:55,766]\u001b[0m A new study created in memory with name: no-name-902a6ced-1264-4624-b1f3-60b057ad16ae\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "sampled_params: {'nn_width': 112, 'dropout': 0.2, 'momentum': 0.02, 'virtual_batch_size': 256, 'weight_decay': 1e-06, 'pct_start': 0.30000000000000004}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6535422576ec419a89513393526df5c2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='SNN', max=50.0, style=ProgressStyle(description_width='in…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lVKLlPgOIXj"
      },
      "source": [
        "***"
      ]
    }
  ]
}